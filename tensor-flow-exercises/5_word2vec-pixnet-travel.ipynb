{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.0.2\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.9 (default, Jun 29 2016 13:08:31)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.3-src.zip'))\n",
    "execfile(os.path.join(spark_home, 'python/pyspark/shell.py'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = sc.textFile(\"/net/account/pixuser/kent/work/pixinterest/grouping/data/article_seq_text_travel/p*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_stop(ws):\n",
    "    r = []\n",
    "    stop={\"\"}\n",
    "    for w in ws:\n",
    "        if w not in stop:\n",
    "            r.append(w)\n",
    "    return r\n",
    "            \n",
    "doc = raw.map(lambda x : x.split(\" \")).map(filter_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TOP_N = 100000\n",
    "top_term = doc.flatMap(lambda x : x).filter(\n",
    "    lambda x:x not in {\"\",}).map(\n",
    "    lambda x : (x,1)).reduceByKey(\n",
    "    lambda x,y : x+y).takeOrdered(TOP_N,key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2indx={}\n",
    "index2word=[w[0] for w in top_term]\n",
    "for idx,w in enumerate(index2word):\n",
    "    word2indx[w] = idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def content_indexing(data):\n",
    "    r = []\n",
    "    for w in data:\n",
    "        if w in word2indx:\n",
    "            r.append(word2indx[w])\n",
    "        else:\n",
    "            r.append(-1)\n",
    "    return r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pairs(content):\n",
    "    pairs =[]\n",
    "    for i in range(1,len(content)-1):\n",
    "        if content[i]==-1 or content[i-1]==-1 or content[i+1]==-1: continue\n",
    "        pairs.append((content[i],content[i-1]))\n",
    "        pairs.append((content[i],content[i+1]))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "term_pair = doc.map(content_indexing).map(get_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_size = TOP_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def doc2onebatch(content):\n",
    "    data = []\n",
    "    label = []\n",
    "    row = {}\n",
    "    for d,l in content:\n",
    "        data.append(d)\n",
    "        label.append([l])\n",
    "    row['data'] = data\n",
    "    row['label'] = label\n",
    "    \n",
    "    return json.dumps(row)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -rvf ./pixnet_word2vec_travel/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "term_pair.map(doc2onebatch).saveAsTextFile(\"./pixnet_word2vec_travel/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 設計 Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-a0ea8686b866>:50 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "batch_size = 128\n",
    "embedding_size = 128 # Dimension of the embedding vector.\n",
    "skip_window = 1 # How many words to consider left and right.\n",
    "num_skips = 2 # How many times to reuse an input to generate a label.\n",
    "# We pick a random validation set to sample nearest neighbors. here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent. \n",
    "valid_size = 16 # Random set of words to evaluate similarity on.\n",
    "valid_window = 100 # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.array(random.sample(xrange(valid_window), valid_size))\n",
    "num_sampled = 64 # Number of negative examples to sample.\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  train_dataset = tf.placeholder(tf.int32, shape=[None])\n",
    "  train_labels = tf.placeholder(tf.int32, shape=[None, 1])\n",
    "  valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "  \n",
    "  # Variables.\n",
    "  embeddings = tf.Variable(\n",
    "    tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "  softmax_weights = tf.Variable(\n",
    "    tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                         stddev=1.0 / math.sqrt(embedding_size)))\n",
    "  softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "  \n",
    "  # Model.\n",
    "  # Look up embeddings for inputs.\n",
    "  embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n",
    "  # Compute the softmax loss, using a sample of the negative labels each time.\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.sampled_softmax_loss(softmax_weights, softmax_biases, embed,\n",
    "                               train_labels, num_sampled, vocabulary_size))\n",
    "\n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n",
    "  \n",
    "  # Compute the similarity between minibatch examples and all embeddings.\n",
    "  # We use the cosine distance:\n",
    "  norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "  normalized_embeddings = embeddings / norm\n",
    "  valid_embeddings = tf.nn.embedding_lookup(\n",
    "    normalized_embeddings, valid_dataset)\n",
    "  similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))\n",
    "  init = tf.initialize_all_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session = tf.Session(graph=graph)\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(batch_data,batch_labels):\n",
    "    feed_dict = {train_dataset : batch_data, train_labels : batch_labels}\n",
    "    _, l = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            if 'crc' in fname : continue\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.05037\n",
      "Nearest to 餐廳: 餐館, 庭園餐廳, 自助餐廳, 海鮮餐廳, 景觀餐廳, 中餐廳, 高級餐廳, 吃到飽餐廳,\n",
      "Nearest to 不過: 只不過, 但是, 可是, 然而, 坦白說, 而且, 總之, 況且,\n",
      "Nearest to 民宿: 旅館, 旅店, 旅社, 我們的民宿, 名宿, 旅宿, 飯店, 青旅,\n",
      "Nearest to 這個: 這一個, 那個, 這各, 這幾個, 這座, 這小, 這塊, 這些,\n",
      "Nearest to 應該: 因該, 肯定, 恐怕, 搞不好, 鐵定, 應該是, 似乎, 也許,\n",
      "Nearest to 地方: 地方啊, 之地, 之處, 地方真, 地方呢, 地方了, 地方要, 地方啦,\n",
      "Nearest to 房間: 房內, 客房, 房裡, 房型, 臥房, 浴室, 臥室, 房門,\n",
      "Nearest to 不知道: 不曉得, 不知, 真不知道, 真不知, 搞不懂, 看不出, 知要, 到底,\n",
      "Nearest to 覺得: 認為, 我覺, 感到, 我認為, 感覺, 不覺得, 絕得, 感覺到,\n",
      "Nearest to 附近: 周圍, 周邊, 週遭, 週邊, 鄰近, 周遭, 週圍, 旁邊,\n",
      "Nearest to 時間: 集合時間, 停留時間, 天數, 時日, 期限, 休息時間, 時數, 時光,\n",
      "Nearest to 之後: 以後, 然後, 過後, 完成後, 後會, 爾後, 而後, 後接,\n",
      "Nearest to 拍照: 照相, 照像, 拍照片, 猛拍, 拍拍, 自拍, 可拍照, 合照,\n",
      "Nearest to 所以: 因此, 於是乎, 以致, 以至於, 所以是, 因而, 導致, 於是就,\n",
      "Nearest to 日本: 本當, 國外, 歐洲, 韓國, 英國, 看日本, 泰國, 日本的,\n",
      "Nearest to 我們: 我門, 偶們, 咱們, 我倆, 為我們, megumi, 我们, 田田,\n",
      "1000 2.68187\n",
      "Nearest to 餐廳: 餐館, 庭園餐廳, 自助餐廳, 海鮮餐廳, 中餐廳, 景觀餐廳, 高級餐廳, 咖啡屋,\n",
      "Nearest to 不過: 只不過, 但是, 然而, 可是, 坦白說, 而且, 總之, 況且,\n",
      "Nearest to 民宿: 旅館, 旅店, 旅社, 我們的民宿, 名宿, 旅宿, 飯店, 青旅,\n",
      "Nearest to 這個: 這一個, 那個, 這各, 這幾個, 這小, 這座, 這些, 這塊,\n",
      "Nearest to 應該: 因該, 肯定, 恐怕, 搞不好, 應該是, 鐵定, 似乎, 或許,\n",
      "Nearest to 地方: 之處, 地方啊, 之地, 地方真, 地方要, 地方了, 地方呢, 地方啦,\n",
      "Nearest to 房間: 房內, 客房, 房型, 房裡, 臥房, 浴室, 房門, 臥室,\n",
      "Nearest to 不知道: 不曉得, 不知, 真不知道, 真不知, 搞不懂, 到底, 看不出, 知要,\n",
      "Nearest to 覺得: 認為, 我覺, 感到, 我認為, 感覺, 不覺得, 絕得, 認為是,\n",
      "Nearest to 附近: 周圍, 周邊, 週遭, 週邊, 鄰近, 周遭, 週圍, 旁邊,\n",
      "Nearest to 時間: 集合時間, 停留時間, 天數, 時日, 期限, 休息時間, 時光, 時數,\n",
      "Nearest to 之後: 以後, 過後, 後會, 然後, 完成後, 爾後, 而後, 後接,\n",
      "Nearest to 拍照: 照相, 照像, 拍照片, 猛拍, 拍拍, 自拍, 可拍照, 合照,\n",
      "Nearest to 所以: 因此, 於是乎, 以致, 以至於, 所以是, 因而, 也就是說, 導致,\n",
      "Nearest to 日本: 本當, 國外, 歐洲, 韓國, 英國, 看日本, 泰國, 日本的,\n",
      "Nearest to 我們: 我門, 偶們, 咱們, 我倆, 為我們, megumi, 我们, 田田,\n",
      "2000 3.32512\n",
      "Nearest to 餐廳: 餐館, 庭園餐廳, 自助餐廳, 海鮮餐廳, 中餐廳, 景觀餐廳, 高級餐廳, 咖啡屋,\n",
      "Nearest to 不過: 只不過, 但是, 然而, 可是, 坦白說, 而且, 總之, 況且,\n",
      "Nearest to 民宿: 旅館, 旅店, 旅社, 我們的民宿, 名宿, 旅宿, 飯店, 青旅,\n",
      "Nearest to 這個: 這一個, 那個, 這各, 這幾個, 這座, 這小, 這些, 這塊,\n",
      "Nearest to 應該: 因該, 肯定, 恐怕, 搞不好, 鐵定, 應該是, 似乎, 其實,\n",
      "Nearest to 地方: 地方啊, 之處, 之地, 地方真, 地方要, 地方了, 地方呢, 地方啦,\n",
      "Nearest to 房間: 房內, 客房, 房型, 房裡, 臥房, 浴室, 房門, 臥室,\n",
      "Nearest to 不知道: 不曉得, 不知, 真不知道, 真不知, 搞不懂, 知要, 看不出, 到底,\n",
      "Nearest to 覺得: 認為, 我覺, 感到, 我認為, 不覺得, 感覺, 絕得, 認為是,\n",
      "Nearest to 附近: 周圍, 周邊, 週遭, 週邊, 周遭, 週圍, 鄰近, 旁邊,\n",
      "Nearest to 時間: 集合時間, 停留時間, 天數, 時日, 期限, 休息時間, 時數, 時光,\n",
      "Nearest to 之後: 以後, 然後, 過後, 完成後, 爾後, 後會, 後接, 而後,\n",
      "Nearest to 拍照: 照相, 照像, 拍照片, 猛拍, 拍拍, 自拍, 合照, 拍個,\n",
      "Nearest to 所以: 因此, 於是乎, 以致, 以至於, 所以是, 因而, 導致, 也就是說,\n",
      "Nearest to 日本: 本當, 歐洲, 國外, 英國, 韓國, 看日本, 日本的, 泰國,\n",
      "Nearest to 我們: 我門, 偶們, 咱們, 我倆, 為我們, megumi, 我们, 大夥,\n",
      "3000 3.29077\n",
      "Nearest to 餐廳: 餐館, 庭園餐廳, 自助餐廳, 景觀餐廳, 海鮮餐廳, 中餐廳, 高級餐廳, 咖啡屋,\n",
      "Nearest to 不過: 只不過, 但是, 可是, 然而, 坦白說, 而且, 況且, 總之,\n",
      "Nearest to 民宿: 旅館, 旅店, 旅社, 我們的民宿, 名宿, 旅宿, 飯店, 青旅,\n",
      "Nearest to 這個: 這一個, 那個, 這各, 這幾個, 這座, 這小, 這塊, 這些,\n",
      "Nearest to 應該: 因該, 肯定, 恐怕, 搞不好, 鐵定, 應該是, 似乎, 其實,\n",
      "Nearest to 地方: 地方啊, 之處, 地方真, 之地, 地方要, 地方了, 地方呢, 地方啦,\n",
      "Nearest to 房間: 房內, 客房, 房裡, 房型, 臥房, 浴室, 房門, 臥室,\n",
      "Nearest to 不知道: 不曉得, 不知, 真不知道, 真不知, 搞不懂, 看不出, 知要, 到底,\n",
      "Nearest to 覺得: 認為, 我覺, 感到, 我認為, 不覺得, 感覺, 絕得, 感覺到,\n",
      "Nearest to 附近: 周邊, 週遭, 周圍, 週邊, 鄰近, 週圍, 周遭, 旁邊,\n",
      "Nearest to 時間: 集合時間, 停留時間, 天數, 時日, 期限, 時數, 休息時間, 時光,\n",
      "Nearest to 之後: 以後, 過後, 然後, 爾後, 完成後, 後會, 而後, 後接,\n",
      "Nearest to 拍照: 照相, 照像, 拍照片, 猛拍, 拍拍, 自拍, 可拍照, 拍個,\n",
      "Nearest to 所以: 因此, 於是乎, 以致, 以至於, 所以是, 因而, 導致, 於是就,\n",
      "Nearest to 日本: 本當, 國外, 歐洲, 英國, 韓國, 看日本, 日本的, 泰國,\n",
      "Nearest to 我們: 我門, 偶們, 咱們, 我倆, 為我們, megumi, 我们, 阿吉,\n",
      "4000 2.98772\n",
      "Nearest to 餐廳: 餐館, 庭園餐廳, 自助餐廳, 海鮮餐廳, 景觀餐廳, 中餐廳, 高級餐廳, 咖啡屋,\n",
      "Nearest to 不過: 只不過, 但是, 然而, 可是, 坦白說, 而且, 況且, 總之,\n",
      "Nearest to 民宿: 旅店, 旅館, 旅社, 我們的民宿, 名宿, 旅宿, 飯店, 青旅,\n",
      "Nearest to 這個: 這一個, 那個, 這各, 這幾個, 這座, 這小, 這塊, 這些,\n",
      "Nearest to 應該: 因該, 肯定, 恐怕, 搞不好, 鐵定, 應該是, 其實, 似乎,\n",
      "Nearest to 地方: 地方啊, 之處, 之地, 地方真, 地方呢, 地方了, 地方要, 地方啦,\n",
      "Nearest to 房間: 房內, 客房, 房型, 房裡, 臥房, 浴室, 臥室, 房門,\n",
      "Nearest to 不知道: 不曉得, 不知, 真不知道, 真不知, 搞不懂, 看不出, 到底, 知要,\n",
      "Nearest to 覺得: 認為, 我覺, 感到, 我認為, 不覺得, 感覺, 絕得, 感覺到,\n",
      "Nearest to 附近: 周邊, 週遭, 周圍, 週邊, 鄰近, 週圍, 周遭, 旁邊,\n",
      "Nearest to 時間: 集合時間, 停留時間, 天數, 時日, 期限, 時數, 休息時間, 時機,\n",
      "Nearest to 之後: 以後, 過後, 然後, 完成後, 爾後, 後會, 後接, 而後,\n",
      "Nearest to 拍照: 照相, 照像, 拍照片, 猛拍, 拍拍, 自拍, 可拍照, 拍攝,\n",
      "Nearest to 所以: 因此, 於是乎, 以致, 以至於, 所以是, 因而, 導致, 於是就,\n",
      "Nearest to 日本: 本當, 歐洲, 國外, 韓國, 看日本, 英國, 日本的, 美國,\n",
      "Nearest to 我們: 我門, 偶們, 咱們, 我倆, 為我們, megumi, 我们, 田田,\n",
      "5000 3.30285\n",
      "Nearest to 餐廳: 餐館, 庭園餐廳, 自助餐廳, 景觀餐廳, 海鮮餐廳, 中餐廳, 高級餐廳, 咖啡屋,\n",
      "Nearest to 不過: 只不過, 但是, 可是, 然而, 坦白說, 而且, 總之, 況且,\n",
      "Nearest to 民宿: 旅館, 旅店, 旅社, 我們的民宿, 名宿, 飯店, 旅宿, 青旅,\n",
      "Nearest to 這個: 這一個, 那個, 這各, 這幾個, 這座, 這小, 這塊, 某個,\n",
      "Nearest to 應該: 因該, 肯定, 恐怕, 搞不好, 鐵定, 應該是, 似乎, 也許,\n",
      "Nearest to 地方: 之地, 地方啊, 之處, 地方真, 地方呢, 地方了, 地方要, 地方啦,\n",
      "Nearest to 房間: 房內, 客房, 房型, 房裡, 臥房, 浴室, 臥室, 房門,\n",
      "Nearest to 不知道: 不曉得, 不知, 真不知道, 真不知, 搞不懂, 知要, 到底, 看不出,\n",
      "Nearest to 覺得: 我覺, 認為, 感到, 我認為, 不覺得, 感覺, 絕得, 感覺到,\n",
      "Nearest to 附近: 周邊, 週遭, 週邊, 周圍, 鄰近, 週圍, 周遭, 旁邊,\n",
      "Nearest to 時間: 集合時間, 停留時間, 天數, 時日, 期限, 時數, 休息時間, 時機,\n",
      "Nearest to 之後: 以後, 過後, 完成後, 後會, 然後, 爾後, 後接, 而後,\n",
      "Nearest to 拍照: 照相, 照像, 拍照片, 猛拍, 拍拍, 自拍, 可拍照, 合照,\n",
      "Nearest to 所以: 因此, 於是乎, 以致, 以至於, 所以是, 因而, 導致, 也就是說,\n",
      "Nearest to 日本: 本當, 國外, 歐洲, 韓國, 英國, 看日本, 美國, 日本的,\n",
      "Nearest to 我們: 我門, 咱們, 偶們, 我倆, 為我們, megumi, 我们, 田田,\n",
      "6000 2.75265\n",
      "Nearest to 餐廳: 餐館, 庭園餐廳, 自助餐廳, 景觀餐廳, 海鮮餐廳, 中餐廳, 高級餐廳, 咖啡屋,\n",
      "Nearest to 不過: 只不過, 但是, 可是, 然而, 坦白說, 而且, 總之, 況且,\n",
      "Nearest to 民宿: 旅館, 旅店, 旅社, 我們的民宿, 名宿, 飯店, 旅宿, 青旅,\n",
      "Nearest to 這個: 這一個, 那個, 這各, 這幾個, 這座, 這小, 某個, 這塊,\n",
      "Nearest to 應該: 因該, 肯定, 恐怕, 搞不好, 鐵定, 應該是, 似乎, 大概,\n",
      "Nearest to 地方: 之處, 之地, 地方啊, 地方真, 地方要, 地方了, 地方呢, 地方啦,\n",
      "Nearest to 房間: 房內, 客房, 房型, 臥房, 房裡, 浴室, 臥室, 房門,\n",
      "Nearest to 不知道: 不曉得, 不知, 真不知道, 真不知, 搞不懂, 看不出, 知要, 搞不清楚,\n",
      "Nearest to 覺得: 認為, 我覺, 感到, 我認為, 不覺得, 感覺, 絕得, 認為是,\n",
      "Nearest to 附近: 周邊, 週遭, 週邊, 周圍, 鄰近, 周遭, 週圍, 旁邊,\n",
      "Nearest to 時間: 集合時間, 時日, 停留時間, 天數, 期限, 時數, 休息時間, 時機,\n",
      "Nearest to 之後: 以後, 然後, 過後, 完成後, 後會, 後接, 爾後, 而後,\n",
      "Nearest to 拍照: 照相, 照像, 拍照片, 猛拍, 拍拍, 可拍照, 自拍, 合照,\n",
      "Nearest to 所以: 因此, 於是乎, 以致, 以至於, 因而, 所以是, 導致, 於是就,\n",
      "Nearest to 日本: 本當, 國外, 歐洲, 英國, 韓國, 美國, 看日本, 來日,\n",
      "Nearest to 我們: 我門, 咱們, 偶們, 我倆, 為我們, megumi, 我们, 阿吉,\n",
      "7000 3.05936\n",
      "Nearest to 餐廳: 餐館, 庭園餐廳, 自助餐廳, 景觀餐廳, 海鮮餐廳, 中餐廳, 高級餐廳, 咖啡屋,\n",
      "Nearest to 不過: 只不過, 但是, 然而, 可是, 坦白說, 而且, 總之, 老實說,\n",
      "Nearest to 民宿: 旅館, 旅店, 旅社, 我們的民宿, 名宿, 旅宿, 青旅, 飯店,\n",
      "Nearest to 這個: 這一個, 那個, 這各, 這幾個, 這座, 這小, 這塊, 某個,\n",
      "Nearest to 應該: 因該, 肯定, 恐怕, 搞不好, 鐵定, 應該是, 似乎, 大概,\n",
      "Nearest to 地方: 之處, 地方啊, 之地, 地方真, 地方要, 地方呢, 地方了, 地方啦,\n",
      "Nearest to 房間: 房內, 客房, 房型, 房裡, 臥房, 浴室, 房門, 臥室,\n",
      "Nearest to 不知道: 不曉得, 不知, 真不知道, 真不知, 搞不懂, 知要, 到底, 看不出,\n",
      "Nearest to 覺得: 認為, 我覺, 感到, 我認為, 不覺得, 感覺, 絕得, 認為是,\n",
      "Nearest to 附近: 周邊, 週邊, 週遭, 周圍, 鄰近, 週圍, 周遭, 旁邊,\n",
      "Nearest to 時間: 集合時間, 停留時間, 時日, 天數, 期限, 時數, 時光, 休息時間,\n",
      "Nearest to 之後: 以後, 然後, 過後, 完成後, 後會, 爾後, 後接, 而後,\n",
      "Nearest to 拍照: 照相, 照像, 拍照片, 猛拍, 拍拍, 自拍, 可拍照, 拍攝,\n",
      "Nearest to 所以: 因此, 於是乎, 以致, 以至於, 因而, 所以是, 於是就, 導致,\n",
      "Nearest to 日本: 本當, 歐洲, 國外, 英國, 美國, 韓國, 看日本, 泰國,\n",
      "Nearest to 我們: 我門, 咱們, 偶們, 我倆, 為我們, megumi, 我们, 阿吉,\n",
      "8000 3.02485\n",
      "Nearest to 餐廳: 餐館, 庭園餐廳, 自助餐廳, 海鮮餐廳, 景觀餐廳, 中餐廳, 高級餐廳, 咖啡屋,\n",
      "Nearest to 不過: 只不過, 但是, 然而, 可是, 坦白說, 而且, 總之, 況且,\n",
      "Nearest to 民宿: 旅館, 旅店, 旅社, 我們的民宿, 名宿, 旅宿, 飯店, 青旅,\n",
      "Nearest to 這個: 這一個, 那個, 這各, 這幾個, 這座, 這小, 這些, 某個,\n",
      "Nearest to 應該: 因該, 肯定, 恐怕, 搞不好, 鐵定, 應該是, 似乎, 其實,\n",
      "Nearest to 地方: 之處, 之地, 地方啊, 地方要, 地方真, 地方呢, 地方了, 地方啦,\n",
      "Nearest to 房間: 房內, 客房, 房型, 臥房, 房裡, 浴室, 臥室, 房門,\n",
      "Nearest to 不知道: 不曉得, 不知, 真不知道, 真不知, 搞不懂, 到底, 看不出, 知要,\n",
      "Nearest to 覺得: 認為, 我覺, 感到, 我認為, 不覺得, 感覺, 絕得, 認為是,\n",
      "Nearest to 附近: 周邊, 週邊, 週遭, 周圍, 鄰近, 週圍, 周遭, 旁邊,\n",
      "Nearest to 時間: 集合時間, 停留時間, 天數, 時日, 期限, 時數, 時光, 時機,\n",
      "Nearest to 之後: 以後, 然後, 過後, 完成後, 爾後, 後會, 而後, 後接,\n",
      "Nearest to 拍照: 照相, 照像, 拍照片, 猛拍, 拍拍, 可拍照, 自拍, 拍攝,\n",
      "Nearest to 所以: 因此, 於是乎, 以致, 以至於, 因而, 所以是, 導致, 於是就,\n",
      "Nearest to 日本: 歐洲, 本當, 國外, 英國, 韓國, 美國, 看日本, 日本的,\n",
      "Nearest to 我們: 我門, 咱們, 偶們, 我倆, 為我們, megumi, 我们, 阿吉,\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    ms = MySentences(\"./pixnet_word2vec_travel//\")\n",
    "    for idx , line in enumerate(ms):\n",
    "        d = json.loads(line)\n",
    "        data = d['data']\n",
    "        if len(data)==0 : continue\n",
    "        label = d['label']\n",
    "        lost = train(data,label)\n",
    "        if idx % 1000 ==0 : \n",
    "            print idx,lost\n",
    "\n",
    "    #         feed_dict = {train_dataset : batch_data, train_labels : batch_labels}\n",
    "\n",
    "            sim = session.run(similarity)\n",
    "            for i in xrange(valid_size):\n",
    "                valid_word = index2word[valid_examples[i]]\n",
    "                top_k = 8 # number of nearest neighbors\n",
    "                nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "                log = \"Nearest to %s:\" % valid_word\n",
    "                for k in xrange(top_k):\n",
    "                  close_word = index2word[nearest[k]]\n",
    "                  log = \"%s %s,\" % (log, close_word)\n",
    "                print log    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_embeddings = session.run(normalized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PixWord2Vec:\n",
    "    index2word\n",
    "    word2indx\n",
    "    final_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixw = PixWord2Vec()\n",
    "pixw.index2word = index2word\n",
    "pixw.word2indx = word2indx\n",
    "pixw.final_embeddings = final_embeddings\n",
    "\n",
    "import pickle\n",
    "pickle.dump(pixw, open(\"./pixword_travel.pk\",'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppixw = pickle.load(open(\"./pixword.pk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0K1ZyLn04QZf"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "import zipfile\n",
    "from matplotlib import pylab\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCjPJE944bkV"
   },
   "source": [
    "Download the data from the source website if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import plotly.plotly as py\n",
    "\n",
    "account = []\n",
    "\n",
    "_account, _pw = account[randint(0, len(account)-1)]\n",
    "py.sign_in(_account, _pw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "jjJXYA_XzV79"
   },
   "outputs": [],
   "source": [
    "num_points = 1000\n",
    "\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "two_d_embeddings = tsne.fit_transform(final_embeddings[1:num_points+1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = [index2word[i] for i in xrange(1, num_points+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~carolpix/383.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "for xvalue,yvalue in two_d_embeddings:\n",
    "    x.append(xvalue)\n",
    "    y.append(yvalue)\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "# Create a trace\n",
    "trace = go.Scatter(\n",
    "    x = x,\n",
    "    y = y,\n",
    "    text = words,\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "py.iplot(data, filename='basic-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colabVersion": "0.3.2",
  "colab_default_view": {},
  "colab_views": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
