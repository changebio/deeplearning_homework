{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原始資料來源的 SQL，這是抽樣過的資料，當中也有一筆資料是修改過的，因為當天 Server 似乎出了一些問題，導至流量大符下降\n",
    "```sql\n",
    "SELECT \n",
    "date,count(distinct cookie_pta) as uv\n",
    "from\n",
    "TABLE_DATE_RANGE(XXX_Table, TIMESTAMP('2017-01-01'), CURRENT_TIMESTAMP())\n",
    "group by date\n",
    "order by date\n",
    "``` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2016-08-25    48844\n",
      "2016-08-26    45711\n",
      "2016-08-27    45016\n",
      "2016-08-28    44743\n",
      "2016-08-29    46924\n",
      "Name: uv, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQwSHIAiCoIYIDkEQBEEN/wMRTcrZHiROLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff78c9d9f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load and plot dataset\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y%m%d')\n",
    "\n",
    "\n",
    "series = read_csv('./data/pixnet_uv_sample.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# summarize first few rows\n",
    "print(series.head())\n",
    "# line plot\n",
    "series.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 進行 scale to 0-1 ，方便作為 input 及 output (因為 sigmoid 介於 0~1 之間)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale,MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape([x.shape[0],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0IIYcTcYDIYW5P8DKv94t55lhvwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff70812a9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(x_scaled)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 產生 x,y pair \n",
    "* 舉列來說假設將 Step Size 設為 4 天，故一筆 Training Data ，為連續 4 天的流量。再來利用這４天的資料來預測第 5 天的流舉\n",
    "* 綠色的部是 Training Data(前4天的資料)，藍色的部份是需要被預測的部份。示意如下圖\n",
    "* <img align=\"left\" width=\"50%\" src=\"./imgs/sequence_uv.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#往回看 30 天前的每一筆資料\n",
    "step_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料長度:(436, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"原始資料長度:{}\".format(x_scaled.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_stack(a, stepsize=1, width=3):\n",
    "    return np.hstack( a[i:1+i-width or None:stepsize] for i in range(0,width) )\n",
    "\n",
    "import numpy as np\n",
    "train_x = window_stack(x_scaled, stepsize=1, width=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 15)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最後一筆資料要放棄，因為沒有未來的答案作驗證\n",
    "\n",
    "train_x = train_x[:-1]\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 請注意千萬不將每一筆(Row) 當中的最後一天資料作為 Training Data 中的 Input Data\n",
    "train_y = np.array([i for i in x_scaled[step_size:]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 確認產出來的 Training Data 沒有包含到 Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.86594605,  0.71476138,  0.68122376,  0.66804999,  0.77329537,\n",
       "        0.71099744,  0.70202191,  0.77319886,  0.70346957,  0.53332047,\n",
       "        0.73662115,  0.7644646 ,  0.7965063 ,  0.83400087,  0.71138349])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71476138,  0.68122376,  0.66804999,  0.77329537,  0.71099744,\n",
       "        0.70202191,  0.77319886,  0.70346957,  0.53332047,  0.73662115,\n",
       "        0.7644646 ,  0.7965063 ,  0.83400087,  0.71138349,  0.73913043])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73913043])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(train_x, (train_x.shape[0], step_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 4)                 96        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import LSTM,Dense\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "# input_shape(step_size,feature_dim)\n",
    "model.add(LSTM(4, input_shape=(step_size,1), unroll=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最後30 筆資料不要看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 3s 7ms/step - loss: 0.2662 - acc: 0.0028 - val_loss: 0.1139 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 613us/step - loss: 0.2146 - acc: 0.0028 - val_loss: 0.0840 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 617us/step - loss: 0.1679 - acc: 0.0028 - val_loss: 0.0587 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.1271 - acc: 0.0028 - val_loss: 0.0383 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 610us/step - loss: 0.0927 - acc: 0.0028 - val_loss: 0.0230 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0649 - acc: 0.0028 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0440 - acc: 0.0055 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0297 - acc: 0.0028 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0214 - acc: 0.0028 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0174 - acc: 0.0028 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0159 - acc: 0.0028 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0154 - acc: 0.0028 - val_loss: 0.0133 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0152 - acc: 0.0028 - val_loss: 0.0134 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0152 - acc: 0.0028 - val_loss: 0.0131 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0151 - acc: 0.0028 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0151 - acc: 0.0028 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0151 - acc: 0.0028 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0150 - acc: 0.0028 - val_loss: 0.0123 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0150 - acc: 0.0028 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0149 - acc: 0.0028 - val_loss: 0.0121 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 589us/step - loss: 0.0149 - acc: 0.0028 - val_loss: 0.0120 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 592us/step - loss: 0.0149 - acc: 0.0028 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0148 - acc: 0.0028 - val_loss: 0.0118 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0148 - acc: 0.0028 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0147 - acc: 0.0028 - val_loss: 0.0115 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0147 - acc: 0.0028 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0147 - acc: 0.0028 - val_loss: 0.0113 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0146 - acc: 0.0028 - val_loss: 0.0112 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0146 - acc: 0.0028 - val_loss: 0.0111 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0146 - acc: 0.0028 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0145 - acc: 0.0028 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0145 - acc: 0.0028 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0145 - acc: 0.0028 - val_loss: 0.0107 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 617us/step - loss: 0.0144 - acc: 0.0028 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0144 - acc: 0.0028 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0144 - acc: 0.0028 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0143 - acc: 0.0028 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0143 - acc: 0.0028 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 591us/step - loss: 0.0143 - acc: 0.0028 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0142 - acc: 0.0028 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0142 - acc: 0.0028 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0142 - acc: 0.0028 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0141 - acc: 0.0028 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0141 - acc: 0.0028 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 593us/step - loss: 0.0141 - acc: 0.0028 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 606us/step - loss: 0.0141 - acc: 0.0028 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0140 - acc: 0.0028 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0140 - acc: 0.0028 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0140 - acc: 0.0028 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0140 - acc: 0.0028 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0140 - acc: 0.0028 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0139 - acc: 0.0028 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0139 - acc: 0.0028 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0139 - acc: 0.0028 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0139 - acc: 0.0028 - val_loss: 0.0090 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0138 - acc: 0.0028 - val_loss: 0.0090 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0138 - acc: 0.0028 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 618us/step - loss: 0.0138 - acc: 0.0028 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 611us/step - loss: 0.0138 - acc: 0.0028 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0138 - acc: 0.0028 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0138 - acc: 0.0028 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0137 - acc: 0.0028 - val_loss: 0.0086 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0137 - acc: 0.0028 - val_loss: 0.0086 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0137 - acc: 0.0028 - val_loss: 0.0085 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0137 - acc: 0.0028 - val_loss: 0.0085 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0137 - acc: 0.0028 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0137 - acc: 0.0028 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0136 - acc: 0.0028 - val_loss: 0.0083 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 610us/step - loss: 0.0136 - acc: 0.0028 - val_loss: 0.0083 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0136 - acc: 0.0028 - val_loss: 0.0082 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 619us/step - loss: 0.0136 - acc: 0.0028 - val_loss: 0.0082 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0136 - acc: 0.0028 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0136 - acc: 0.0028 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 593us/step - loss: 0.0136 - acc: 0.0028 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 590us/step - loss: 0.0136 - acc: 0.0028 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0135 - acc: 0.0028 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0135 - acc: 0.0028 - val_loss: 0.0079 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0135 - acc: 0.0028 - val_loss: 0.0079 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0135 - acc: 0.0028 - val_loss: 0.0079 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0135 - acc: 0.0028 - val_loss: 0.0078 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 617us/step - loss: 0.0135 - acc: 0.0028 - val_loss: 0.0078 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 614us/step - loss: 0.0135 - acc: 0.0028 - val_loss: 0.0078 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 741us/step - loss: 0.0135 - acc: 0.0028 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 640us/step - loss: 0.0135 - acc: 0.0028 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 667us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 682us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0076 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 639us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0076 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0076 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 622us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 627us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 632us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 724us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 646us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0134 - acc: 0.0028 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0072 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0072 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0072 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0072 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0072 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 621us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0072 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 621us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0072 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 627us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 631us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0133 - acc: 0.0028 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 613us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 590us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 625us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 621us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 613us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0132 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 618us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 617us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 613us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 622us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 617us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 590us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 611us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 611us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 610us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 612us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 614us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 613us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 593us/step - loss: 0.0131 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 618us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 631us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 620us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 622us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 611us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 585us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 590us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 591us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0130 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 610us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 593us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 612us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 626us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 622us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 613us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 619us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 618us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 634us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0129 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 613us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 625us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 618us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 633us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 613us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 611us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0128 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 610us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 611us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 593us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 622us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 612us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 607us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 618us/step - loss: 0.0127 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 589us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 612us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 635us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 623us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 634us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 618us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 591us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 587us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 614us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 590us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 605us/step - loss: 0.0126 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 616us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 614us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 618us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 622us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 593us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 611us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 621us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 618us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 589us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 612us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 610us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 618us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 617us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 613us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 610us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 621us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 629us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0125 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 612us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 612us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 597us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 590us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 628us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 611us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 654us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 702us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 587us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 592us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 643us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 622us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 676us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0124 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 628us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 649us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 626us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 610us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 593us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 592us/step - loss: 0.0123 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 598us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 593us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 624us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 619us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 592us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 592us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0122 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 616us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 614us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 593us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 636us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 618us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0121 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 625us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 610us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 616us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 618us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 619us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 605us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 617us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 616us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 614us/step - loss: 0.0120 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 625us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 611us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 617us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 621us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 613us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 625us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 641us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 589us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 591us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 593us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 591us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 596us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 616us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 575us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0119 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 583us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 616us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 627us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 610us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 622us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 593us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 620us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 623us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 641us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 611us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 588us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 602us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 585us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 612us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 610us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0118 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 637us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 635us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 644us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 632us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 592us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 613us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 603us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 616us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 611us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 624us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 611us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 608us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 634us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 610us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 603us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 617us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 598us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 594us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 615us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 629us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 616us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 606us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 625us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 620us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0117 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 593us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 603us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 597us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 604us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 601us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 600us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 602us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 609us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 649us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 693us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 595us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 596us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 603us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 599us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 607us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 605us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "361/361 [==============================] - 0s 627us/step - loss: 0.0116 - acc: 0.0028 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Train on 361 samples, validate on 60 samples\n",
      "Epoch 1/1\n",
      "256/361 [====================>.........] - ETA: 0s - loss: 0.0111 - acc: 0.0039   "
     ]
    }
   ],
   "source": [
    "val_loss = []\n",
    "loss = []\n",
    "for _ in range(1000):\n",
    "    history = model.fit(trainX[:-1*validation_size],\n",
    "              train_y[:-1*validation_size],\n",
    "              epochs=1,shuffle=False, \n",
    "              validation_data=(trainX[-1*validation_size:],\n",
    "              train_y[-1*validation_size:]))\n",
    "    \n",
    "    loss.append(history.history['loss'])\n",
    "    val_loss.append(history.history['val_loss'])\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 看一下 Error Rate 曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(loss)\n",
    "pyplot.plot(val_loss)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 看一下曲線擬合效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = model.predict(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(scaler.inverse_transform(predict_y))\n",
    "pyplot.plot(scaler.inverse_transform(train_y))\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 來預測最後 30天資料預出來的結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = model.predict(trainX[-1*validation_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = scaler.inverse_transform(predict_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(predict_y)\n",
    "pyplot.plot(x[-1*(validation_size+1):-1])\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 心得觀察\n",
    "* LSTM 可以學習到 Period Pattern 是沒有問題的，但是似乎對於大幅的震盪以目前的 Model 來說無法完全的 Catch 到，但是還是有學到漲幅的趨勢預測\n",
    "* 至於 LSTM 要如何調整震盪的幅度有兩個想法可以實驗看看\n",
    " * 直接 Modified Training，將震盪幅度加大\n",
    " * 修改 Loss Function ，把平方改為 2.x 次方不知道是否有效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
