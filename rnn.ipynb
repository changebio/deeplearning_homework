{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import sys\n",
    "from itertools import izip\n",
    "import time\n",
    "\n",
    "# Min/max sequence length\n",
    "MIN_LENGTH = 50\n",
    "MAX_LENGTH = 55\n",
    "# Number of units in the hidden (recurrent) layer\n",
    "N_HIDDEN = 100\n",
    "# input\n",
    "N_INPUT = 2\n",
    "# output\n",
    "N_OUTPUT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 55\n",
    "x_seq = np.concatenate([np.random.uniform(size=(length, 1)),\n",
    "                        np.zeros((length, 1))],\n",
    "                       axis=-1)\n",
    "x_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from https://github.com/Lasagne/Lasagne/blob/master/examples/recurrent.py\n",
    "def gen_data(min_length=MIN_LENGTH, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    Generate a sequences for the \"add\" task, e.g. the target for the\n",
    "    following\n",
    "    ``| 0.5 | 0.7 | 0.3 | 0.1 | 0.2 | ... | 0.5 | 0.9 | ... | 0.8 | 0.2 |\n",
    "      |  0  |  0  |  1  |  0  |  0  |     |  0  |  1  |     |  0  |  0  |``\n",
    "    would be 0.3 + .9 = 1.2.  This task was proposed in [1]_ and explored in\n",
    "    e.g. [2]_.\n",
    "    Parameters\n",
    "    ----------\n",
    "    min_length : int\n",
    "        Minimum sequence length.\n",
    "    max_length : int\n",
    "        Maximum sequence length.\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.ndarray\n",
    "        Input to the network, of shape (length, 2), where the last\n",
    "        dimension corresponds to the two sequences shown above.\n",
    "    y : np.ndarray\n",
    "        Correct output for each sample (a scalar).\n",
    "    '''\n",
    "    # Generate x_seq\n",
    "    length = np.random.randint(min_length, max_length)\n",
    "    x_seq = np.concatenate([np.random.uniform(size=(length, 1)),\n",
    "                        np.zeros((length, 1))],\n",
    "                       axis=-1)\n",
    "    # Set the second dimension to 1 at the indices to add\n",
    "    x_seq[np.random.randint(length/10), 1] = 1\n",
    "    x_seq[np.random.randint(length/2, length), 1] = 1\n",
    "    # Multiply and sum the dimensions of x_seq to get the target value\n",
    "    y_hat = np.sum(x_seq[:, 0]*x_seq[:, 1])\n",
    "    return x_seq,y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "# what can we get from gen_data()\n",
    "x_seq ,y_hat = gen_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width='400px' src='./rnn.png' />\n",
    "<img width='400px' src='./rnn-step.png' />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_seq = T.matrix('input')\n",
    "y_hat = T.scalar('target')\n",
    "\n",
    "Wi = theano.shared( np.random.randn(N_INPUT,N_HIDDEN) )\n",
    "bh = theano.shared( np.zeros(N_HIDDEN) )\n",
    "Wo = theano.shared( np.random.randn(N_HIDDEN,N_OUTPUT) )\n",
    "bo = theano.shared( np.zeros(N_OUTPUT) )\n",
    "Wh = theano.shared( np.random.randn(N_HIDDEN,N_HIDDEN) )\n",
    "parameters = [Wi,bh,Wo,bo,Wh]\n",
    "\n",
    "def sigmoid(z):\n",
    "        return 1/(1+T.exp(-z))\n",
    "\n",
    "def step(x_t,a_tm1,y_tm1):\n",
    "        a_t = sigmoid( T.dot(x_t,Wi) \\\n",
    "                + T.dot(a_tm1,Wh) + bh )\n",
    "        y_t = T.dot(a_t,Wo) + bo\n",
    "        return a_t, y_t\n",
    "\n",
    "a_0 = theano.shared(np.zeros(N_HIDDEN))\n",
    "y_0 = theano.shared(np.zeros(N_OUTPUT))\n",
    "\n",
    "[a_seq,y_seq],_ = theano.scan(\n",
    "                        step,\n",
    "                        sequences = x_seq,\n",
    "                        outputs_info = [ a_0, y_0 ],\n",
    "\t\t\ttruncate_gradient=-1\n",
    "                )\n",
    "\n",
    "y_seq_last = y_seq[-1][0] # we only care about the last output \n",
    "cost = T.sum( ( y_seq_last - y_hat )**2 ) \n",
    "\n",
    "gradients = T.grad(cost,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/theano/scan_module/scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "def MyUpdate(parameters,gradients):\n",
    "\tmu =  np.float32(0.001)\n",
    "\tparameters_updates = [(p,p - mu * g) for p,g in izip(parameters,gradients) ] \n",
    "\treturn parameters_updates\n",
    "\n",
    "rnn_test = theano.function(\n",
    "        inputs= [x_seq],\n",
    "        outputs=y_seq_last\n",
    ")\n",
    "\n",
    "rnn_train = theano.function(\n",
    "        inputs=[x_seq,y_hat],\n",
    "        outputs=cost,\n",
    "\tupdates=MyUpdate(parameters,gradients)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 cost: 1.87286049796\n",
      "iteration: 100000 cost: 0.0389489752921\n",
      "iteration: 200000 cost: 0.767482507614\n",
      "iteration: 300000 cost: 0.656512680759\n",
      "iteration: 400000 cost: 1.03579989708\n",
      "iteration: 500000 cost: 0.00297750277748\n",
      "iteration: 600000 cost: 0.445865545077\n",
      "iteration: 700000 cost: 2.08940234897\n",
      "iteration: 800000 cost: 1.66911791592\n",
      "iteration: 900000 cost: 0.126490677392\n",
      "iteration: 1000000 cost: 1.66585286845\n",
      "iteration: 1100000 cost: 0.625987674831\n",
      "iteration: 1200000 cost: 0.221164682048\n",
      "iteration: 1300000 cost: 0.00148957367261\n",
      "iteration: 1400000 cost: 0.433307887547\n",
      "iteration: 1500000 cost: 0.149722065831\n",
      "iteration: 1600000 cost: 0.73590279033\n",
      "iteration: 1700000 cost: 0.00307003183073\n",
      "iteration: 1800000 cost: 0.981170515097\n",
      "iteration: 1900000 cost: 0.147502216936\n",
      "iteration: 2000000 cost: 0.00174814090118\n",
      "iteration: 2100000 cost: 0.376269839506\n",
      "iteration: 2200000 cost: 1.73209036336\n",
      "iteration: 2300000 cost: 0.698531307932\n",
      "iteration: 2400000 cost: 1.14444918992\n",
      "iteration: 2500000 cost: 0.0961373672755\n",
      "iteration: 2600000 cost: 0.183457927067\n",
      "iteration: 2700000 cost: 0.0952867604475\n",
      "iteration: 2800000 cost: 0.0255292756676\n",
      "iteration: 2900000 cost: 0.426547848991\n",
      "iteration: 3000000 cost: 0.911406570249\n",
      "iteration: 3100000 cost: 0.000811440527163\n",
      "iteration: 3200000 cost: 0.897421133472\n",
      "iteration: 3300000 cost: 0.0046912163744\n",
      "iteration: 3400000 cost: 0.073653707562\n",
      "iteration: 3500000 cost: 0.206008547282\n",
      "iteration: 3600000 cost: 0.473701240862\n",
      "iteration: 3700000 cost: 0.875146743651\n",
      "iteration: 3800000 cost: 0.121687664153\n",
      "iteration: 3900000 cost: 0.896743147024\n",
      "iteration: 4000000 cost: 1.29871687521\n",
      "iteration: 4100000 cost: 0.0446126490992\n",
      "iteration: 4200000 cost: 0.0124028588274\n",
      "iteration: 4300000 cost: 0.192058093502\n",
      "iteration: 4400000 cost: 0.558883050075\n",
      "iteration: 4500000 cost: 0.014962553831\n",
      "iteration: 4600000 cost: 2.54273039566\n",
      "iteration: 4700000 cost: 0.0458725229759\n",
      "iteration: 4800000 cost: 0.124405781074\n",
      "iteration: 4900000 cost: 0.0340911133947\n",
      "iteration: 5000000 cost: 0.0936385923082\n",
      "iteration: 5100000 cost: 0.0996965164512\n",
      "iteration: 5200000 cost: 0.529142738207\n",
      "iteration: 5300000 cost: 0.0816798424586\n",
      "iteration: 5400000 cost: 0.0367016449533\n",
      "iteration: 5500000 cost: 0.0313456433992\n",
      "iteration: 5600000 cost: 0.000798195818473\n",
      "iteration: 5700000 cost: 1.06253318094\n",
      "iteration: 5800000 cost: 0.172246405945\n",
      "iteration: 5900000 cost: 0.14991254263\n",
      "iteration: 6000000 cost: 0.683307873023\n",
      "iteration: 6100000 cost: 0.335676258284\n",
      "iteration: 6200000 cost: 0.126042111707\n",
      "iteration: 6300000 cost: 0.437718471684\n",
      "iteration: 6400000 cost: 0.00235435150369\n",
      "iteration: 6500000 cost: 0.436090921764\n",
      "iteration: 6600000 cost: 0.258281763399\n",
      "iteration: 6700000 cost: 1.26629624734\n",
      "iteration: 6800000 cost: 1.28015027251\n",
      "iteration: 6900000 cost: 1.05946507128\n",
      "iteration: 7000000 cost: 0.0388814561072\n",
      "iteration: 7100000 cost: 1.28963952317\n",
      "iteration: 7200000 cost: 0.116940506889\n",
      "iteration: 7300000 cost: 0.00622146344814\n",
      "iteration: 7400000 cost: 0.111581974207\n",
      "iteration: 7500000 cost: 0.0036697364885\n",
      "iteration: 7600000 cost: 1.12757194416\n",
      "iteration: 7700000 cost: 0.419178358218\n",
      "iteration: 7800000 cost: 1.52166655616\n",
      "iteration: 7900000 cost: 0.236638864884\n",
      "iteration: 8000000 cost: 0.00264923419209\n",
      "iteration: 8100000 cost: 0.00111881764131\n",
      "iteration: 8200000 cost: 2.61640134408\n",
      "iteration: 8300000 cost: 0.0783955688722\n",
      "iteration: 8400000 cost: 0.2959904577\n",
      "iteration: 8500000 cost: 0.190857389366\n",
      "iteration: 8600000 cost: 1.1981451787\n",
      "iteration: 8700000 cost: 1.70202994034\n",
      "iteration: 8800000 cost: 0.150202669853\n",
      "iteration: 8900000 cost: 0.00284343339953\n",
      "iteration: 9000000 cost: 1.06019228374\n",
      "iteration: 9100000 cost: 0.000318670985926\n",
      "iteration: 9200000 cost: 0.658238908656\n",
      "iteration: 9300000 cost: 0.144854716289\n",
      "iteration: 9400000 cost: 0.365991682259\n",
      "iteration: 9500000 cost: 0.383501481928\n",
      "iteration: 9600000 cost: 0.49472891963\n",
      "iteration: 9700000 cost: 0.0861976391317\n",
      "iteration: 9800000 cost: 1.31128844565\n",
      "iteration: 9900000 cost: 0.468320616385\n",
      "reference 1.54033756968 RNN output: 0.272876282057\n",
      "reference 1.17738962037 RNN output: -0.0813829394505\n",
      "reference 1.09915456056 RNN output: 0.850807454882\n",
      "reference 1.09455493873 RNN output: 0.6619255452\n",
      "reference 1.93601082667 RNN output: 0.931238929968\n",
      "reference 1.27667596184 RNN output: 0.259754832396\n",
      "reference 0.980468677136 RNN output: 0.826522217602\n",
      "reference 1.14623902191 RNN output: 0.862092651957\n",
      "reference 1.09843568801 RNN output: 0.0944187299582\n",
      "reference 1.06004031755 RNN output: 0.370242420224\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000000):\n",
    "    x_seq, y_hat = gen_data()\n",
    "    if i % 100000 == 0:\n",
    "        print \"iteration:\", i, \"cost:\",  rnn_train(x_seq,y_hat)\n",
    "\n",
    "for i in range(10):\n",
    "\tx_seq, y_hat = gen_data()\n",
    "\tprint \"reference\", y_hat, \"RNN output:\", rnn_test(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
